{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38500aa6",
   "metadata": {},
   "source": [
    "# BK Classification Inference Notebook\n",
    "\n",
    "This notebook loads the best-performing 2-stage BART model and provides an interface for classifying bibliographic records with BK codes.\n",
    "\n",
    "**Model**: Two-Stage BART (25.7% subset accuracy, 0.498 MCC)  \n",
    "**Checkpoint**: `bart_classifier_bart-large_bs64_e15_sALL_2stage_bart_20250811_000132`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070aeda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, BartModel\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2caac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture defined.\n"
     ]
    }
   ],
   "source": [
    "class BartWithClassifier(nn.Module):\n",
    "    \"\"\"BART classifier for multi-label BK classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_labels=1884, model_name=\"facebook/bart-large\", dropout=0.1):\n",
    "        super(BartWithClassifier, self).__init__()\n",
    "        \n",
    "        self.num_labels = num_labels\n",
    "        self.bart = BartModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bart.config.hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.bart(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        cls_output = last_hidden_state[:, 0, :]  # Take [CLS] token representation\n",
    "        cls_output = self.dropout(cls_output)\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits\n",
    "\n",
    "print(\"Model architecture defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160457cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading label mapping...\n",
      "Loaded 1884 BK labels\n",
      "Sample labels: ['01.00', '01.20', '01.22', '01.29', '01.30', '01.40', '02.00', '02.01', '02.02', '02.10']\n"
     ]
    }
   ],
   "source": [
    "# Model paths\n",
    "MODEL_DIR = \"results/bart_classifier_bart-large_bs64_e15_sALL_2stage_bart_20250811_000132\"\n",
    "MODEL_PATH = f\"{MODEL_DIR}/checkpoints_stage2/best_model_15.pt\"\n",
    "LABEL_MAP_PATH = \"data/label_map.json\"\n",
    "\n",
    "# Load label mapping\n",
    "print(\"Loading label mapping...\")\n",
    "with open(LABEL_MAP_PATH, 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "# Create reverse mapping (index -> label)\n",
    "idx_to_label = {v: k for k, v in label_map.items()}\n",
    "num_labels = len(label_map)\n",
    "\n",
    "print(f\"Loaded {num_labels} BK labels\")\n",
    "print(f\"Sample labels: {list(label_map.keys())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b30c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Loading trained weights...\n",
      "Checkpoint keys: ['epoch', 'model_state', 'optimizer_state', 'best_metric', 'monitor_metric']\n",
      "Loaded model from epoch 15\n",
      "Best metric: 0.21449027735603707\n",
      "Monitor metric: f1_macro\n",
      "Model loaded and ready for inference!\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "model = BartWithClassifier(num_labels=num_labels, model_name=\"facebook/bart-large\")\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading trained weights...\")\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "\n",
    "# Print checkpoint keys to debug\n",
    "print(\"Checkpoint keys:\", list(checkpoint.keys()))\n",
    "\n",
    "# Handle different checkpoint formats\n",
    "if 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded model from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "elif 'model_state' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    print(f\"Loaded model from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "elif 'state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(f\"Loaded model from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "else:\n",
    "    # If it's just the raw state dict\n",
    "    try:\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print(\"Loaded raw state dict\")\n",
    "    except:\n",
    "        print(\"ERROR: Could not determine checkpoint format\")\n",
    "        print(\"Available keys:\", list(checkpoint.keys()))\n",
    "        raise\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Model loaded and ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7347d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Tokenizer loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "print(\"Tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b2335c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preprocessed text:\n",
      "Title: Machine Learning in Practice\n",
      "Summary: A comprehensive guide to machine learning applications\n",
      "Keywords: machine learning, artificial intelligence\n",
      "LOC_Keywords: \n",
      "RVK:\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(title=\"\", summary=\"\", keywords=\"\", loc_keywords=\"\", rvk=\"\", author=\"\"):\n",
    "    \"\"\"\n",
    "    Preprocess bibliographic fields into the format expected by the model.\n",
    "    \n",
    "    Args:\n",
    "        title: Book title\n",
    "        summary: Book summary/abstract\n",
    "        keywords: Subject keywords\n",
    "        loc_keywords: Library of Congress keywords\n",
    "        rvk: RVK classification codes\n",
    "        author: Author information (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted text string for model input\n",
    "    \"\"\"\n",
    "    # Combine fields in the same format as training\n",
    "    input_text = f\"\"\"Title: {title or ''}\n",
    "Summary: {summary or ''}\n",
    "Keywords: {keywords or ''}\n",
    "LOC_Keywords: {loc_keywords or ''}\n",
    "RVK: {rvk or ''}\"\"\"\n",
    "\n",
    "    \n",
    "    return input_text.strip()\n",
    "\n",
    "# Test preprocessing\n",
    "test_text = preprocess_text(\n",
    "    title=\"Machine Learning in Practice\",\n",
    "    summary=\"A comprehensive guide to machine learning applications\",\n",
    "    keywords=\"machine learning, artificial intelligence\"\n",
    ")\n",
    "print(\"Sample preprocessed text:\")\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "981fc35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction functions ready.\n"
     ]
    }
   ],
   "source": [
    "def predict_bk_codes(text: str, \n",
    "                     threshold: float = 0.5, \n",
    "                     top_k: int = 10,\n",
    "                     max_length: int = 768) -> Dict:\n",
    "    \"\"\"\n",
    "    Predict BK classification codes for input text.\n",
    "    \n",
    "    Args:\n",
    "        text: Preprocessed input text\n",
    "        threshold: Probability threshold for positive predictions\n",
    "        top_k: Return top-k predictions regardless of threshold\n",
    "        max_length: Maximum input sequence length\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing predictions and metadata\n",
    "    \"\"\"\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probabilities = torch.sigmoid(logits).cpu().numpy()[0]  # Get probabilities\n",
    "    \n",
    "    # Get predictions above threshold\n",
    "    threshold_predictions = []\n",
    "    for idx, prob in enumerate(probabilities):\n",
    "        if prob >= threshold:\n",
    "            threshold_predictions.append({\n",
    "                'label': idx_to_label[idx],\n",
    "                'probability': float(prob),\n",
    "                'confidence': 'High' if prob > 0.8 else 'Medium' if prob > 0.6 else 'Low'\n",
    "            })\n",
    "    \n",
    "    # Sort by probability\n",
    "    threshold_predictions.sort(key=lambda x: x['probability'], reverse=True)\n",
    "    \n",
    "    # Get top-k predictions (regardless of threshold)\n",
    "    top_indices = np.argsort(probabilities)[-top_k:][::-1]\n",
    "    top_k_predictions = []\n",
    "    for idx in top_indices:\n",
    "        top_k_predictions.append({\n",
    "            'label': idx_to_label[idx],\n",
    "            'probability': float(probabilities[idx]),\n",
    "            'confidence': 'High' if probabilities[idx] > 0.8 else 'Medium' if probabilities[idx] > 0.6 else 'Low'\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'threshold_predictions': threshold_predictions,\n",
    "        'top_k_predictions': top_k_predictions,\n",
    "        'num_above_threshold': len(threshold_predictions),\n",
    "        'max_probability': float(np.max(probabilities)),\n",
    "        'threshold_used': threshold,\n",
    "        'input_length': len(input_ids[0])\n",
    "    }\n",
    "\n",
    "print(\"Prediction functions ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e72350d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display functions ready.\n"
     ]
    }
   ],
   "source": [
    "def display_predictions(predictions: Dict, show_top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Display prediction results in a formatted way.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BK CLASSIFICATION RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"Input length: {predictions['input_length']} tokens\")\n",
    "    print(f\"Max probability: {predictions['max_probability']:.4f}\")\n",
    "    print(f\"Threshold used: {predictions['threshold_used']}\")\n",
    "    print(f\"Predictions above threshold: {predictions['num_above_threshold']}\")\n",
    "    \n",
    "    # Show threshold-based predictions\n",
    "    if predictions['threshold_predictions']:\n",
    "        print(f\"\\nüìä PREDICTIONS ABOVE THRESHOLD ({predictions['threshold_used']})\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, pred in enumerate(predictions['threshold_predictions'][:show_top_k], 1):\n",
    "            print(f\"{i:2d}. {pred['label']:15s} | {pred['probability']:.4f} | {pred['confidence']}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No predictions above threshold {predictions['threshold_used']}\")\n",
    "    \n",
    "    # Show top-k predictions\n",
    "    print(f\"\\nüîù TOP {show_top_k} PREDICTIONS (regardless of threshold)\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, pred in enumerate(predictions['top_k_predictions'][:show_top_k], 1):\n",
    "        marker = \"‚úì\" if pred['probability'] >= predictions['threshold_used'] else \" \"\n",
    "        print(f\"{marker} {i:2d}. {pred['label']:15s} | {pred['probability']:.4f} | {pred['confidence']}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "\n",
    "def get_bk_category_info(bk_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Get general category information for a BK code.\n",
    "    \"\"\"\n",
    "    # Extract main category (before dot)\n",
    "    main_cat = bk_code.split('.')[0]\n",
    "    \n",
    "    # General BK category mapping (simplified)\n",
    "    bk_categories = {\n",
    "        '00': 'Computer Science, Knowledge & General',\n",
    "        '02': 'Librarianship, Information Science',\n",
    "        '05': 'Communication, Mass Media',\n",
    "        '10': 'Philosophy',\n",
    "        '11': 'Theology',\n",
    "        '15': 'Psychology',\n",
    "        '17': 'Ethics',\n",
    "        '18': 'Ancient Philosophy',\n",
    "        '20': 'Education',\n",
    "        '24': 'Education',\n",
    "        '30': 'Sociology',\n",
    "        '31': 'Politics',\n",
    "        '33': 'Economics',\n",
    "        '34': 'Law',\n",
    "        '35': 'Public Administration',\n",
    "        '38': 'Ethnology, Cultural Anthropology',\n",
    "        '39': 'Folklore',\n",
    "        '43': 'German Language & Literature',\n",
    "        '50': 'Mathematics',\n",
    "        '53': 'Physics',\n",
    "        '54': 'Chemistry',\n",
    "        '57': 'Biology',\n",
    "        '58': 'Botany',\n",
    "        '59': 'Zoology',\n",
    "        '61': 'Medicine',\n",
    "        '69': 'Architecture, Construction',\n",
    "        '70': 'Agriculture',\n",
    "        '76': 'Technology',\n",
    "        '83': 'Economics',\n",
    "        '85': 'Education',\n",
    "        '86': 'Law',\n",
    "        '89': 'Political Science'\n",
    "    }\n",
    "    \n",
    "    return bk_categories.get(main_cat, f\"Category {main_cat}\")\n",
    "\n",
    "print(\"Display functions ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b9d8dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT TEXT:\n",
      "Title: Deep Learning with PyTorch\n",
      "Summary: This book provides a comprehensive introduction to deep learning using PyTorch framework. It covers neural networks, convolutional networks, and natural language processing applications.\n",
      "Keywords: deep learning, neural networks, PyTorch, machine learning, artificial intelligence\n",
      "LOC_Keywords: Computer algorithms, Machine learning\n",
      "RVK:\n",
      "\n",
      "============================================================\n",
      "BK CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "Input length: 78 tokens\n",
      "Max probability: 0.9676\n",
      "Threshold used: 0.3\n",
      "Predictions above threshold: 1\n",
      "\n",
      "üìä PREDICTIONS ABOVE THRESHOLD (0.3)\n",
      "--------------------------------------------------\n",
      " 1. 54.72           | 0.9676 | High\n",
      "\n",
      "üîù TOP 5 PREDICTIONS (regardless of threshold)\n",
      "--------------------------------------------------\n",
      "‚úì  1. 54.72           | 0.9676 | High\n",
      "   2. 54.53           | 0.2489 | Low\n",
      "   3. 31.73           | 0.0846 | Low\n",
      "   4. 54.62           | 0.0403 | Low\n",
      "   5. 54.80           | 0.0137 | Low\n",
      "\n",
      "============================================================\n",
      "\n",
      "üìö CATEGORY INFORMATION:\n",
      "  54.72 ‚Üí Chemistry\n",
      "  54.53 ‚Üí Chemistry\n",
      "  31.73 ‚Üí Politics\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Computer Science\n",
    "text1 = preprocess_text(\n",
    "    title=\"Deep Learning with PyTorch\",\n",
    "    summary=\"This book provides a comprehensive introduction to deep learning using PyTorch framework. It covers neural networks, convolutional networks, and natural language processing applications.\",\n",
    "    keywords=\"deep learning, neural networks, PyTorch, machine learning, artificial intelligence\",\n",
    "    loc_keywords=\"Computer algorithms, Machine learning\",\n",
    "    author=\"Smith, John\"\n",
    ")\n",
    "\n",
    "print(\"INPUT TEXT:\")\n",
    "print(text1)\n",
    "\n",
    "# Make predictions with different thresholds\n",
    "predictions1 = predict_bk_codes(text1, threshold=0.3, top_k=10)\n",
    "display_predictions(predictions1)\n",
    "\n",
    "# Show category information for top predictions\n",
    "print(\"\\nüìö CATEGORY INFORMATION:\")\n",
    "for pred in predictions1['top_k_predictions'][:3]:\n",
    "    category = get_bk_category_info(pred['label'])\n",
    "    print(f\"  {pred['label']} ‚Üí {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6709b4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT TEXT:\n",
      "Title: Clinical Cardiology: A Modern Approach\n",
      "Summary: A comprehensive textbook covering contemporary approaches to cardiovascular disease diagnosis and treatment. Includes latest research on heart failure, arrhythmias, and interventional cardiology.\n",
      "Keywords: cardiology, heart disease, clinical medicine, cardiovascular\n",
      "LOC_Keywords: Cardiology, Heart diseases\n",
      "RVK:\n",
      "\n",
      "============================================================\n",
      "BK CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "Input length: 74 tokens\n",
      "Max probability: 0.9862\n",
      "Threshold used: 0.25\n",
      "Predictions above threshold: 1\n",
      "\n",
      "üìä PREDICTIONS ABOVE THRESHOLD (0.25)\n",
      "--------------------------------------------------\n",
      " 1. 44.85           | 0.9862 | High\n",
      "\n",
      "üîù TOP 5 PREDICTIONS (regardless of threshold)\n",
      "--------------------------------------------------\n",
      "‚úì  1. 44.85           | 0.9862 | High\n",
      "   2. 44.84           | 0.0369 | Low\n",
      "   3. 44.38           | 0.0336 | Low\n",
      "   4. 44.87           | 0.0180 | Low\n",
      "   5. 44.37           | 0.0176 | Low\n",
      "\n",
      "============================================================\n",
      "\n",
      "üìö CATEGORY INFORMATION:\n",
      "  44.85 ‚Üí Category 44\n",
      "  44.84 ‚Üí Category 44\n",
      "  44.38 ‚Üí Category 44\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Medicine\n",
    "text2 = preprocess_text(\n",
    "    title=\"Clinical Cardiology: A Modern Approach\",\n",
    "    summary=\"A comprehensive textbook covering contemporary approaches to cardiovascular disease diagnosis and treatment. Includes latest research on heart failure, arrhythmias, and interventional cardiology.\",\n",
    "    keywords=\"cardiology, heart disease, clinical medicine, cardiovascular\",\n",
    "    loc_keywords=\"Cardiology, Heart diseases\"\n",
    ")\n",
    "\n",
    "print(\"INPUT TEXT:\")\n",
    "print(text2)\n",
    "\n",
    "predictions2 = predict_bk_codes(text2, threshold=0.25, top_k=10)\n",
    "display_predictions(predictions2)\n",
    "\n",
    "# Show category information\n",
    "print(\"\\nüìö CATEGORY INFORMATION:\")\n",
    "for pred in predictions2['top_k_predictions'][:3]:\n",
    "    category = get_bk_category_info(pred['label'])\n",
    "    print(f\"  {pred['label']} ‚Üí {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d6c463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOUR INPUT TEXT:\n",
      "Title: Quantum Computing Fundamentals\n",
      "Summary: An introduction to quantum computing principles, quantum algorithms, and quantum information theory.\n",
      "Keywords: quantum computing, quantum algorithms, quantum information\n",
      "LOC_Keywords: Quantum theory, Computer science\n",
      "RVK:\n",
      "\n",
      "============================================================\n",
      "BK CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "Input length: 54 tokens\n",
      "Max probability: 0.9412\n",
      "Threshold used: 0.25\n",
      "Predictions above threshold: 2\n",
      "\n",
      "üìä PREDICTIONS ABOVE THRESHOLD (0.25)\n",
      "--------------------------------------------------\n",
      " 1. 54.10           | 0.9412 | High\n",
      " 2. 33.23           | 0.5561 | Low\n",
      "\n",
      "üîù TOP 10 PREDICTIONS (regardless of threshold)\n",
      "--------------------------------------------------\n",
      "‚úì  1. 54.10           | 0.9412 | High\n",
      "‚úì  2. 33.23           | 0.5561 | Low\n",
      "   3. 53.71           | 0.0558 | Low\n",
      "   4. 54.51           | 0.0379 | Low\n",
      "   5. 54.01           | 0.0277 | Low\n",
      "   6. 33.06           | 0.0242 | Low\n",
      "   7. 54.70           | 0.0180 | Low\n",
      "   8. 54.38           | 0.0172 | Low\n",
      "   9. 54.25           | 0.0120 | Low\n",
      "  10. 54.00           | 0.0108 | Low\n",
      "\n",
      "============================================================\n",
      "\n",
      "üìö CATEGORY INFORMATION:\n",
      "  54.10 ‚Üí Chemistry\n",
      "  33.23 ‚Üí Economics\n",
      "  53.71 ‚Üí Physics\n",
      "  54.51 ‚Üí Chemistry\n",
      "  54.01 ‚Üí Chemistry\n"
     ]
    }
   ],
   "source": [
    "# Interactive prediction - modify these fields\n",
    "YOUR_TITLE = \"Quantum Computing Fundamentals\"\n",
    "YOUR_SUMMARY = \"An introduction to quantum computing principles, quantum algorithms, and quantum information theory.\"\n",
    "YOUR_KEYWORDS = \"quantum computing, quantum algorithms, quantum information\"\n",
    "YOUR_LOC_KEYWORDS = \"Quantum theory, Computer science\"\n",
    "YOUR_RVK = \"\"\n",
    "YOUR_AUTHOR = \"\"\n",
    "\n",
    "# Preprocessing\n",
    "your_text = preprocess_text(\n",
    "    title=YOUR_TITLE,\n",
    "    summary=YOUR_SUMMARY,\n",
    "    keywords=YOUR_KEYWORDS,\n",
    "    loc_keywords=YOUR_LOC_KEYWORDS,\n",
    "    rvk=YOUR_RVK,\n",
    "    author=YOUR_AUTHOR\n",
    ")\n",
    "\n",
    "print(\"YOUR INPUT TEXT:\")\n",
    "print(your_text)\n",
    "\n",
    "# Make prediction\n",
    "your_predictions = predict_bk_codes(your_text, threshold=0.25, top_k=15)\n",
    "display_predictions(your_predictions, show_top_k=10)\n",
    "\n",
    "# Category information\n",
    "print(\"\\nüìö CATEGORY INFORMATION:\")\n",
    "for pred in your_predictions['top_k_predictions'][:5]:\n",
    "    category = get_bk_category_info(pred['label'])\n",
    "    print(f\"  {pred['label']} ‚Üí {category}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
