{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BK Classification Inference Notebook - Hugging Face Hub Version\n",
        "\n",
        "This notebook loads the best-performing 2-stage BART model from Hugging Face Hub and provides an interface for classifying bibliographic records with BK codes.\n",
        "\n",
        "**Model**: Two-Stage BART (25.7% subset accuracy, 0.498 MCC)  \n",
        "**Hugging Face**: `mrehank209/bk-classification-bart-two-stage`  \n",
        "**Performance**: Best among 4 modeling strategies tested\n",
        "\n",
        "## Model Performance Summary\n",
        "- **Subset Accuracy**: 25.7%\n",
        "- **MCC**: 0.498\n",
        "- **F1-Micro**: 47.9%\n",
        "- **F1-Macro**: 21.4%\n",
        "- **Precision (Micro)**: 66.1%\n",
        "- **Recall (Micro)**: 37.6%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "GPU available: False\n"
          ]
        }
      ],
      "source": [
        "# Install required packages if not already installed\n",
        "# !pip install torch transformers huggingface_hub numpy pandas\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from transformers import AutoTokenizer, BartModel\n",
        "from huggingface_hub import hf_hub_download\n",
        "from typing import List, Dict, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model architecture defined.\n"
          ]
        }
      ],
      "source": [
        "class BartWithClassifier(nn.Module):\n",
        "    \"\"\"BART classifier for multi-label BK classification\"\"\"\n",
        "    \n",
        "    def __init__(self, num_labels=1884, model_name=\"facebook/bart-large\", dropout=0.1):\n",
        "        super(BartWithClassifier, self).__init__()\n",
        "        \n",
        "        self.num_labels = num_labels\n",
        "        self.bart = BartModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.bart.config.hidden_size, num_labels)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bart(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        cls_output = last_hidden_state[:, 0, :]  # Take [CLS] token representation\n",
        "        cls_output = self.dropout(cls_output)\n",
        "        logits = self.classifier(cls_output)\n",
        "        return logits\n",
        "\n",
        "print(\"Model architecture defined.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from Hugging Face Hub...\n",
            "Repository: mrehank209/bk-classification-bart-two-stage\n",
            "This will work once you upload the model using upload_to_huggingface.py\n",
            "Loading model from Hugging Face Hub: mrehank209/bk-classification-bart-two-stage\n",
            "Downloading model files...\n",
            "Loading configuration...\n",
            "Loading label mappings...\n",
            "Loaded 1884 BK labels\n",
            "Sample labels: ['01.00', '01.20', '01.22', '01.29', '01.30', '01.40', '02.00', '02.01', '02.02', '02.10']\n",
            "Initializing model...\n",
            "Loading classifier weights...\n",
            "Loading tokenizer...\n",
            "Model loaded successfully from Hugging Face Hub!\n",
            "Model Performance:\n",
            "   - Subset Accuracy: 25.7%\n",
            "   - MCC: 0.498\n",
            "   - F1-Micro: 47.9%\n",
            "   - F1-Macro: 21.4%\n"
          ]
        }
      ],
      "source": [
        "def load_model_from_huggingface(model_name=\"mrehank209/bk-classification-bart-two-stage\"):\n",
        "    \"\"\"\n",
        "    Load the complete model from Hugging Face Hub\n",
        "    \n",
        "    Args:\n",
        "        model_name: HuggingFace model repository name\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, label_map, idx_to_label, config)\n",
        "    \"\"\"\n",
        "    print(f\"Loading model from Hugging Face Hub: {model_name}\")\n",
        "    \n",
        "    try:\n",
        "        # Download required files from HF Hub\n",
        "        print(\"Downloading model files...\")\n",
        "        classifier_path = hf_hub_download(repo_id=model_name, filename=\"classifier_head.pt\")\n",
        "        config_path = hf_hub_download(repo_id=model_name, filename=\"config.json\")\n",
        "        label_map_path = hf_hub_download(repo_id=model_name, filename=\"label_map.json\")\n",
        "        idx_to_label_path = hf_hub_download(repo_id=model_name, filename=\"idx_to_label.json\")\n",
        "        \n",
        "        # Load configuration\n",
        "        print(\"Loading configuration...\")\n",
        "        with open(config_path, 'r') as f:\n",
        "            config = json.load(f)\n",
        "        \n",
        "        # Load label mappings\n",
        "        print(\"Loading label mappings...\")\n",
        "        with open(label_map_path, 'r') as f:\n",
        "            label_map = json.load(f)\n",
        "        \n",
        "        with open(idx_to_label_path, 'r') as f:\n",
        "            idx_to_label = json.load(f)\n",
        "            # Convert string keys back to integers\n",
        "            idx_to_label = {int(k): v for k, v in idx_to_label.items()}\n",
        "        \n",
        "        print(f\"Loaded {len(label_map)} BK labels\")\n",
        "        print(f\"Sample labels: {list(label_map.keys())[:10]}\")\n",
        "        \n",
        "        # Initialize model with correct number of labels\n",
        "        print(\"Initializing model...\")\n",
        "        model = BartWithClassifier(\n",
        "            num_labels=config[\"num_labels\"],\n",
        "            model_name=config[\"base_model\"],\n",
        "            dropout=config[\"dropout\"]\n",
        "        )\n",
        "        \n",
        "        # Load classifier head weights\n",
        "        print(\"Loading classifier weights...\")\n",
        "        classifier_state = torch.load(classifier_path, map_location='cpu')\n",
        "        model.classifier.weight.data = classifier_state['weight']\n",
        "        model.classifier.bias.data = classifier_state['bias']\n",
        "        \n",
        "        # Load tokenizer\n",
        "        print(\"Loading tokenizer...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        \n",
        "        # Move model to device and set to evaluation mode\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        \n",
        "        print(\"Model loaded successfully from Hugging Face Hub!\")\n",
        "        print(f\"Model Performance:\")\n",
        "        print(f\"   - Subset Accuracy: {config['performance']['subset_accuracy']:.1%}\")\n",
        "        print(f\"   - MCC: {config['performance']['mcc']:.3f}\")\n",
        "        print(f\"   - F1-Micro: {config['performance']['f1_micro']:.1%}\")\n",
        "        print(f\"   - F1-Macro: {config['performance']['f1_macro']:.1%}\")\n",
        "        \n",
        "        return model, tokenizer, label_map, idx_to_label, config\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model from Hugging Face: {e}\")\n",
        "        print(\"\"\"\n",
        "🔧 Troubleshooting:\n",
        "1. Make sure the model repository exists and is public\n",
        "2. Check your internet connection\n",
        "3. If using a private model, make sure you're authenticated:\n",
        "   - Run: huggingface-cli login\n",
        "   - Or set HF_TOKEN environment variable\n",
        "        \"\"\")\n",
        "        raise\n",
        "\n",
        "# Load the model\n",
        "print(\"Loading model from Hugging Face Hub...\")\n",
        "print(\"Repository: mrehank209/bk-classification-bart-two-stage\")\n",
        "print(\"This will work once you upload the model using upload_to_huggingface.py\")\n",
        "\n",
        "# Load the model from Hugging Face Hub\n",
        "model, tokenizer, label_map, idx_to_label, config = load_model_from_huggingface()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample preprocessed text (German library book):\n",
            "==================================================\n",
            "Title: Künstliche Intelligenz in der Bibliothek\n",
            "Summary: \n",
            "Keywords: \n",
            "LOC_Keywords: \n",
            "RVK:\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(title=\"\", summary=\"\", keywords=\"\", loc_keywords=\"\", rvk=\"\", author=\"\"):\n",
        "    \"\"\"\n",
        "    Preprocess bibliographic fields into the format expected by the model.\n",
        "    \n",
        "    Args:\n",
        "        title: Book title\n",
        "        summary: Book summary/abstract\n",
        "        keywords: Subject keywords\n",
        "        loc_keywords: Library of Congress keywords\n",
        "        rvk: RVK classification codes\n",
        "        author: Author information (optional, not used in current model)\n",
        "    \n",
        "    Returns:\n",
        "        Formatted text string for model input\n",
        "    \"\"\"\n",
        "    # Combine fields in the same format as training\n",
        "    input_text = f\"\"\"Title: {title or ''}\n",
        "Summary: {summary or ''}\n",
        "Keywords: {keywords or ''}\n",
        "LOC_Keywords: {loc_keywords or ''}\n",
        "RVK: {rvk or ''}\"\"\"\n",
        "    \n",
        "    return input_text.strip()\n",
        "\n",
        "# Test preprocessing with German example\n",
        "test_text = preprocess_text(\n",
        "    title=\"Künstliche Intelligenz in der Bibliothek\",\n",
        "    summary=\"\",\n",
        "    keywords=\"\",\n",
        "    loc_keywords=\"\",\n",
        "    rvk=\"\"\n",
        ")\n",
        "\n",
        "print(\"Sample preprocessed text (German library book):\")\n",
        "print(\"=\" * 50)\n",
        "print(test_text)\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction functions ready.\n",
            "Optimized threshold: 0.25 (based on validation performance)\n",
            "Expected performance: 25.7% subset accuracy, 0.498 MCC\n"
          ]
        }
      ],
      "source": [
        "def predict_bk_codes(text: str, \n",
        "                     threshold: float = 0.25, \n",
        "                     top_k: int = 10,\n",
        "                     max_length: int = 768) -> Dict:\n",
        "    \"\"\"\n",
        "    Predict BK classification codes for input text.\n",
        "    \n",
        "    Args:\n",
        "        text: Preprocessed input text\n",
        "        threshold: Probability threshold for positive predictions (default: 0.25, optimized for this model)\n",
        "        top_k: Return top-k predictions regardless of threshold\n",
        "        max_length: Maximum input sequence length\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary containing predictions and metadata\n",
        "    \"\"\"\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    \n",
        "    # Move to device\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "    \n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        probabilities = torch.sigmoid(logits).cpu().numpy()[0]  # Get probabilities\n",
        "    \n",
        "    # Get predictions above threshold\n",
        "    threshold_predictions = []\n",
        "    for idx, prob in enumerate(probabilities):\n",
        "        if prob >= threshold:\n",
        "            threshold_predictions.append({\n",
        "                'label': idx_to_label[idx],\n",
        "                'probability': float(prob),\n",
        "                'confidence': 'High' if prob > 0.8 else 'Medium' if prob > 0.6 else 'Low'\n",
        "            })\n",
        "    \n",
        "    # Sort by probability\n",
        "    threshold_predictions.sort(key=lambda x: x['probability'], reverse=True)\n",
        "    \n",
        "    # Get top-k predictions (regardless of threshold)\n",
        "    top_indices = np.argsort(probabilities)[-top_k:][::-1]\n",
        "    top_k_predictions = []\n",
        "    for idx in top_indices:\n",
        "        top_k_predictions.append({\n",
        "            'label': idx_to_label[idx],\n",
        "            'probability': float(probabilities[idx]),\n",
        "            'confidence': 'High' if probabilities[idx] > 0.8 else 'Medium' if probabilities[idx] > 0.6 else 'Low'\n",
        "        })\n",
        "    \n",
        "    return {\n",
        "        'threshold_predictions': threshold_predictions,\n",
        "        'top_k_predictions': top_k_predictions,\n",
        "        'num_above_threshold': len(threshold_predictions),\n",
        "        'max_probability': float(np.max(probabilities)),\n",
        "        'threshold_used': threshold,\n",
        "        'input_length': len(input_ids[0]),\n",
        "        'model_info': {\n",
        "            'name': 'Two-Stage BART',\n",
        "            'subset_accuracy': config['performance']['subset_accuracy'],\n",
        "            'mcc': config['performance']['mcc']\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"Prediction functions ready.\")\n",
        "print(f\"Optimized threshold: 0.25 (based on validation performance)\")\n",
        "print(f\"Expected performance: 25.7% subset accuracy, 0.498 MCC\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with sample German library book...\n",
            "\n",
            "============================================================\n",
            "BK CLASSIFICATION RESULTS\n",
            "============================================================\n",
            "Model: Two-Stage BART\n",
            "Expected Accuracy: 25.7% | MCC: 0.498\n",
            "Input length: 39 tokens\n",
            "Max probability: 0.8759\n",
            "Threshold used: 0.5\n",
            "Predictions above threshold: 585\n",
            "\n",
            "PREDICTIONS ABOVE THRESHOLD (0.5)\n",
            "------------------------------------------------------------\n",
            "Rank BK Code         Probability  Confidence\n",
            "------------------------------------------------------------\n",
            "1    48.58           0.8759       H High\n",
            "2    56.11           0.8260       H High\n",
            "3    31.45           0.7921       M Medium\n",
            "4    24.30           0.7812       M Medium\n",
            "5    05.37           0.7777       M Medium\n",
            "6    86.78           0.7726       M Medium\n",
            "7    42.60           0.7658       M Medium\n",
            "8    21.19           0.7583       M Medium\n",
            "\n",
            "TOP-10 PREDICTIONS (Regardless of Threshold)\n",
            "------------------------------------------------------------\n",
            "Rank BK Code         Probability  Confidence\n",
            "------------------------------------------------------------\n",
            "1    48.58           0.8759       H High\n",
            "2    56.11           0.8260       H High\n",
            "3    31.45           0.7921       M Medium\n",
            "4    24.30           0.7812       M Medium\n",
            "5    05.37           0.7777       M Medium\n",
            "6    86.78           0.7726       M Medium\n",
            "7    42.60           0.7658       M Medium\n",
            "8    21.19           0.7583       M Medium\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def display_predictions(predictions: Dict, show_top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Display prediction results in a formatted way.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"BK CLASSIFICATION RESULTS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Model info\n",
        "    model_info = predictions['model_info']\n",
        "    print(f\"Model: {model_info['name']}\")\n",
        "    print(f\"Expected Accuracy: {model_info['subset_accuracy']:.1%} | MCC: {model_info['mcc']:.3f}\")\n",
        "    print(f\"Input length: {predictions['input_length']} tokens\")\n",
        "    print(f\"Max probability: {predictions['max_probability']:.4f}\")\n",
        "    print(f\"Threshold used: {predictions['threshold_used']}\")\n",
        "    print(f\"Predictions above threshold: {predictions['num_above_threshold']}\")\n",
        "    \n",
        "    # Show threshold-based predictions\n",
        "    if predictions['threshold_predictions']:\n",
        "        print(f\"\\nPREDICTIONS ABOVE THRESHOLD ({predictions['threshold_used']})\")\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"{'Rank':<4} {'BK Code':<15} {'Probability':<12} {'Confidence':<10}\")\n",
        "        print(\"-\" * 60)\n",
        "        for i, pred in enumerate(predictions['threshold_predictions'][:show_top_k], 1):\n",
        "            confidence_emoji = \"H\" if pred['confidence'] == 'High' else \"M\" if pred['confidence'] == 'Medium' else \"L\"\n",
        "            print(f\"{i:<4} {pred['label']:<15} {pred['probability']:<12.4f} {confidence_emoji} {pred['confidence']}\")\n",
        "    else:\n",
        "        print(f\"\\nNo predictions above threshold {predictions['threshold_used']}\")\n",
        "    \n",
        "    # Always show top-k predictions\n",
        "    print(f\"\\nTOP-{len(predictions['top_k_predictions'])} PREDICTIONS (Regardless of Threshold)\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Rank':<4} {'BK Code':<15} {'Probability':<12} {'Confidence':<10}\")\n",
        "    print(\"-\" * 60)\n",
        "    for i, pred in enumerate(predictions['top_k_predictions'][:show_top_k], 1):\n",
        "        confidence_emoji = \"H\" if pred['confidence'] == 'High' else \"M\" if pred['confidence'] == 'Medium' else \"L\"\n",
        "        print(f\"{i:<4} {pred['label']:<15} {pred['probability']:<12.4f} {confidence_emoji} {pred['confidence']}\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "\n",
        "# Test with the sample text\n",
        "print(\"Testing with sample German library book...\")\n",
        "sample_predictions = predict_bk_codes(test_text, threshold=0.5)\n",
        "display_predictions(sample_predictions, show_top_k=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example: Computer Science Book\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "BK CLASSIFICATION RESULTS\n",
            "============================================================\n",
            "Model: Two-Stage BART\n",
            "Expected Accuracy: 25.7% | MCC: 0.498\n",
            "Input length: 40 tokens\n",
            "Max probability: 0.8941\n",
            "Threshold used: 0.2\n",
            "Predictions above threshold: 1824\n",
            "\n",
            "PREDICTIONS ABOVE THRESHOLD (0.2)\n",
            "------------------------------------------------------------\n",
            "Rank BK Code         Probability  Confidence\n",
            "------------------------------------------------------------\n",
            "1    48.58           0.8941       H High\n",
            "2    56.11           0.8395       H High\n",
            "3    05.37           0.7959       M Medium\n",
            "4    86.78           0.7935       M Medium\n",
            "5    31.45           0.7935       M Medium\n",
            "\n",
            "TOP-10 PREDICTIONS (Regardless of Threshold)\n",
            "------------------------------------------------------------\n",
            "Rank BK Code         Probability  Confidence\n",
            "------------------------------------------------------------\n",
            "1    48.58           0.8941       H High\n",
            "2    56.11           0.8395       H High\n",
            "3    05.37           0.7959       M Medium\n",
            "4    86.78           0.7935       M Medium\n",
            "5    31.45           0.7935       M Medium\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def classify_bibliographic_record(\n",
        "    title: str,\n",
        "    summary: str = \"\",\n",
        "    keywords: str = \"\",\n",
        "    loc_keywords: str = \"\",\n",
        "    rvk: str = \"\",\n",
        "    threshold: float = 0.5,\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    End-to-end classification function for bibliographic records.\n",
        "    \n",
        "    Args:\n",
        "        title: Book title (required)\n",
        "        summary: Book summary/abstract\n",
        "        keywords: Subject keywords\n",
        "        loc_keywords: Library of Congress keywords\n",
        "        rvk: RVK classification codes\n",
        "        threshold: Probability threshold for predictions\n",
        "        top_k: Number of top predictions to return\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with predictions and input information\n",
        "    \"\"\"\n",
        "    # Preprocess the input\n",
        "    processed_text = preprocess_text(\n",
        "        title=title,\n",
        "        summary=summary,\n",
        "        keywords=keywords,\n",
        "        loc_keywords=loc_keywords,\n",
        "        rvk=rvk\n",
        "    )\n",
        "    \n",
        "    # Make predictions\n",
        "    predictions = predict_bk_codes(\n",
        "        text=processed_text,\n",
        "        threshold=threshold\n",
        "    )\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "# Example usage - you can modify these fields for your own book\n",
        "print(\"Example: Computer Science Book\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "cs_results = classify_bibliographic_record(\n",
        "    title=\"Deep Learning: Grundlagen und praktische Anwendungen\",\n",
        "    summary=\"\",\n",
        "    keywords=\"\",\n",
        "    loc_keywords=\"\",\n",
        "    rvk=\"\",\n",
        "    threshold=0.2  # Lower threshold for more predictions\n",
        ")\n",
        "\n",
        "display_predictions(cs_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Test Your Own Books\n",
        "\n",
        "Modify the cell below to classify your own bibliographic records:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔬 Your Custom Classification:\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "BK CLASSIFICATION RESULTS\n",
            "============================================================\n",
            "Model: Two-Stage BART\n",
            "Expected Accuracy: 25.7% | MCC: 0.498\n",
            "Input length: 35 tokens\n",
            "Max probability: 0.8900\n",
            "Threshold used: 0.5\n",
            "Predictions above threshold: 614\n",
            "\n",
            "PREDICTIONS ABOVE THRESHOLD (0.5)\n",
            "------------------------------------------------------------\n",
            "Rank BK Code         Probability  Confidence\n",
            "------------------------------------------------------------\n",
            "1    48.58           0.8900       H High\n",
            "2    56.11           0.8325       H High\n",
            "3    31.45           0.7917       M Medium\n",
            "4    42.60           0.7898       M Medium\n",
            "5    24.30           0.7872       M Medium\n",
            "\n",
            "TOP-10 PREDICTIONS (Regardless of Threshold)\n",
            "------------------------------------------------------------\n",
            "Rank BK Code         Probability  Confidence\n",
            "------------------------------------------------------------\n",
            "1    48.58           0.8900       H High\n",
            "2    56.11           0.8325       H High\n",
            "3    31.45           0.7917       M Medium\n",
            "4    42.60           0.7898       M Medium\n",
            "5    24.30           0.7872       M Medium\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 📝 Modify these fields for your book:\n",
        "your_book = {\n",
        "    'title': \"Einführung in die Quantenphysik\",\n",
        "    'summary': \"\",\n",
        "    'keywords': \"\",\n",
        "    'loc_keywords': \"\",\n",
        "    'rvk': \"\"\n",
        "}\n",
        "\n",
        "print(\"🔬 Your Custom Classification:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Run classification\n",
        "your_results = classify_bibliographic_record(**your_book)\n",
        "display_predictions(your_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
